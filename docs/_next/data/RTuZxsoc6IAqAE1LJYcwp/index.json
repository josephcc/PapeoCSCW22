{"pageProps":{"papeos":[{"author":"Christina Pan","email":"capan@alumni.stanford.edu ","title":"Comparing the Perceived Legitimacy of Content\nModeration Processes: Contractors, Algorithms, Expert\nPanels, and Digital Juries","status":"Done","link":"https://paper-video-nav.apps.allenai.org/reader/10.1145.3512929","conference":"https://programs.sigchi.org/cscw/2022/index/content/87096","abstract":"While research continues to investigate and improve the accuracy, fairness, and normative appropriateness of content moderation processes on large social media platforms, even the best process cannot be effective if users reject its authority as illegitimate. We present a survey experiment comparing the perceived institutional legitimacy of four popular content moderation processes. We conducted a within-subjects experiment in which we showed US Facebook users moderation decisions and randomized the description of whether those decisions were made by paid contractors, algorithms, expert panels, or juries of users. Prior work suggests that juries will have the highest perceived legitimacy due to the benefits of judicial independence and democratic representation. However, expert panels had greater perceived legitimacy than algorithms or juries. Moreover, outcome alignment—agreement with the decision—played a larger role than process in determining perceived legitimacy. These results suggest benefits to incorporating expert oversight in content moderation and underscore that any process will face legitimacy challenges derived from disagreement about outcomes."},{"author":"Farnaz Jahanbakhsh","email":"farnazj@mit.edu","title":"Leveraging Structured Trusted-Peer Assessments to Combat\nMisinformation","status":"Done","link":"https://paper-video-nav.apps.allenai.org/reader/10.1145.3555637","conference":"https://programs.sigchi.org/cscw/2022/index/content/89614","abstract":"Platform operators have devoted significant effort to combating misinformation on behalf of their users. Users are also stakeholders in this battle, but their efforts to combat misinformation go unsupported by the platforms. In this work, we consider three new user affordances that give social media users greater power in their fight against misinformation: (1) the ability to provide structured accuracy assessments of posts, (2) user-specified indication of trust in other users, and (3) and user configuration of social feed filters according to assessed accuracy. To understand the potential of these designs, we conducted a need-finding survey of 192 people who share and discuss news on social media, finding that many already act to limit or combat misinformation, albeit by repurposing existing platform affordances that lack customized structure for information assessment. We then conducted a field study of a prototype social media platform that implements these user affordances as structured inputs to directly impact how and whether posts are shown. The study involved 14 participants who used the platform for a week to share news while collectively assessing their accuracy. We report on users' perception and use of these affordances. We also provide design implications for platforms and researchers based on our empirical observations."},{"author":"Haesoo Kim","email":"haesoo1108@gmail.com","title":"When Does it Become Harassment?: An Investigation of\nOnline Criticism and Calling Out in Twitter","status":"Done","link":"https://paper-video-nav.apps.allenai.org/reader/1122445.1122456","conference":"https://programs.sigchi.org/cscw/2022/index/content/89477","abstract":"Calling out, a phenomenon where people publicly broadcast their critiques of someone to a larger audience, has become increasingly common on social media. However, there have been concerns that it could develop into harassment, deteriorating the quality of public discourse by over-punishing individuals. To study this, we interviewed 32 Twitter users who had been called out, had called out, or had witnessed a calling out on Twitter. We found that a key determining factor that distinguishes criticism from harassment was the callee’s ability to respond to or engage with the criticism, and that different stakeholders hold different perspectives toward how online harassment is defined. We also discovered that the distinction between callers and callees was not absolute, and that there was high interchangeability of roles both within and across events. Through these findings, we discuss design implications for the platform in promoting healthy discourse while preventing toxic behavior on social media."},{"author":"Prerna Juneja","email":"prerna79@uw.edu","title":"Human and technological infrastructures of fact-checking","status":"Done","link":"https://paper-video-nav.apps.allenai.org/reader/10.1145.3555143","conference":"https://programs.sigchi.org/cscw/2022/index/content/89562","abstract":"Increasing demands for fact-checking have led to a growing interest in developing systems and tools to\nautomate the fact-checking process. However, such systems are limited in practice because their system design\noften does not take into account how fact-checking is done in the real world and ignores the insights and needs\nof various stakeholder groups core to the fact-checking process. This paper unpacks the fact-checking process\nby revealing the infrastructures—both human and technological—that support and shape fact-checking work.\nWe interviewed 26 participants belonging to 16 fact-checking teams and organizations with representation\nfrom 4 continents. Through these interviews, we describe the human infrastructure of fact-checking by\nidentifying and presenting, in-depth, the roles of six primary stakeholder groups, 1) Editors, 2) External\nfact-checkers, 3) In-house fact-checkers, 4) Investigators and researchers, 5) Social media managers, and 6)\nAdvocators. Our findings highlight that the fact-checking process is a collaborative effort among various\nstakeholder groups and associated technological and informational infrastructures. By rendering visibility\nto the infrastructures, we reveal how fact-checking has evolved to include both short-term claims centric\nand long-term advocacy centric fact-checking. Our work also identifies key social and technical needs and\nchallenges faced by each stakeholder group. Based on our findings, we suggest that improving the quality of\nfact-checking requires systematic changes in the civic, informational, and technological contexts."}]},"__N_SSG":true}