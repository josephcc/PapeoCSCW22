{"pageProps":{"papeos":[{"author":"Christina Pan","email":"capan@alumni.stanford.edu ","title":"Comparing the Perceived Legitimacy of Content\nModeration Processes: Contractors, Algorithms, Expert\nPanels, and Digital Juries","status":"Done","link":"https://paper-video-nav.apps.allenai.org/reader/10.1145.3512929","conference":"https://programs.sigchi.org/cscw/2022/index/content/87096","abstract":"While research continues to investigate and improve the accuracy, fairness, and normative appropriateness of content moderation processes on large social media platforms, even the best process cannot be effective if users reject its authority as illegitimate. We present a survey experiment comparing the perceived institutional legitimacy of four popular content moderation processes. We conducted a within-subjects experiment in which we showed US Facebook users moderation decisions and randomized the description of whether those decisions were made by paid contractors, algorithms, expert panels, or juries of users. Prior work suggests that juries will have the highest perceived legitimacy due to the benefits of judicial independence and democratic representation. However, expert panels had greater perceived legitimacy than algorithms or juries. Moreover, outcome alignment—agreement with the decision—played a larger role than process in determining perceived legitimacy. These results suggest benefits to incorporating expert oversight in content moderation and underscore that any process will face legitimacy challenges derived from disagreement about outcomes."},{"author":"Farnaz Jahanbakhsh","email":"farnazj@mit.edu","title":"Leveraging Structured Trusted-Peer Assessments to Combat\nMisinformation","status":"Done","link":"https://paper-video-nav.apps.allenai.org/reader/10.1145.3555637","conference":"https://programs.sigchi.org/cscw/2022/index/content/89614","abstract":"Platform operators have devoted significant effort to combating misinformation on behalf of their users. Users are also stakeholders in this battle, but their efforts to combat misinformation go unsupported by the platforms. In this work, we consider three new user affordances that give social media users greater power in their fight against misinformation: (1) the ability to provide structured accuracy assessments of posts, (2) user-specified indication of trust in other users, and (3) and user configuration of social feed filters according to assessed accuracy. To understand the potential of these designs, we conducted a need-finding survey of 192 people who share and discuss news on social media, finding that many already act to limit or combat misinformation, albeit by repurposing existing platform affordances that lack customized structure for information assessment. We then conducted a field study of a prototype social media platform that implements these user affordances as structured inputs to directly impact how and whether posts are shown. The study involved 14 participants who used the platform for a week to share news while collectively assessing their accuracy. We report on users' perception and use of these affordances. We also provide design implications for platforms and researchers based on our empirical observations."},{"author":"Haesoo Kim","email":"haesoo1108@gmail.com","title":"When Does it Become Harassment?: An Investigation of\nOnline Criticism and Calling Out in Twitter","status":"Done","link":"https://paper-video-nav.apps.allenai.org/reader/1122445.1122456","conference":"https://programs.sigchi.org/cscw/2022/index/content/89477","abstract":"Calling out, a phenomenon where people publicly broadcast their critiques of someone to a larger audience, has become increasingly common on social media. However, there have been concerns that it could develop into harassment, deteriorating the quality of public discourse by over-punishing individuals. To study this, we interviewed 32 Twitter users who had been called out, had called out, or had witnessed a calling out on Twitter. We found that a key determining factor that distinguishes criticism from harassment was the callee’s ability to respond to or engage with the criticism, and that different stakeholders hold different perspectives toward how online harassment is defined. We also discovered that the distinction between callers and callees was not absolute, and that there was high interchangeability of roles both within and across events. Through these findings, we discuss design implications for the platform in promoting healthy discourse while preventing toxic behavior on social media."},{"author":"Soya Park","email":"soya@mit.edu","title":"Exploring Team-Sourced Hyperlinks to Address Navigation\nChallenges for Low-Vision Readers of Scientific Papers","status":"Done","link":"https://paper-video-nav.apps.allenai.org/reader/10.1145.3555629","conference":"https://programs.sigchi.org/cscw/2022/index/content/89660","abstract":"Reading academic papers is a fundamental part of higher education and research, but navigating these\ninformation-dense texts can be challenging. In particular, low-vision readers using magnification encounter\nadditional barriers to quickly skimming and visually locating information. In this work, we explored the design\nof interfaces to enable readers to: 1) navigate papers more easily, and 2) input the required navigation hooks\nthat AI cannot currently automate. To explore this design space, we ran two exploratory studies. The first\nfocused on current practices of low-vision paper readers, the challenges they encounter, and the interfaces they\ndesire. During this study, low-vision participants were interviewed, and tried out four new paper navigation\nprototypes. Results from this study grounded the design of our end-to-end system prototype Ocean, which\nprovides an accessible front-end for low-vision readers, and enables all readers to contribute to the backend by\nleaving traces of their reading paths for others to leverage. Our second study used this exploratory interface\nin a field study with groups of low-vision and sighted readers to probe the user experience of reading and\ncreating traces. Our findings suggest that it may be possible for readers of all abilities to organically leave\ntraces in papers, and that these traces can be used to facilitate navigation tasks, in particular for low-vision\nreaders. Based on our findings, we present design considerations for creating future paper-reading tools that\nimprove access, and organically source the required data from readers."},{"author":"Prerna Juneja","email":"prerna79@uw.edu","title":"Human and Technological Infrastructures of Fact-Checking","status":"Done","link":"https://paper-video-nav.apps.allenai.org/reader/10.1145.3555143","conference":"https://programs.sigchi.org/cscw/2022/index/content/89562","abstract":"Increasing demands for fact-checking have led to a growing interest in developing systems and tools to\nautomate the fact-checking process. However, such systems are limited in practice because their system design\noften does not take into account how fact-checking is done in the real world and ignores the insights and needs\nof various stakeholder groups core to the fact-checking process. This paper unpacks the fact-checking process\nby revealing the infrastructures—both human and technological—that support and shape fact-checking work.\nWe interviewed 26 participants belonging to 16 fact-checking teams and organizations with representation\nfrom 4 continents. Through these interviews, we describe the human infrastructure of fact-checking by\nidentifying and presenting, in-depth, the roles of six primary stakeholder groups, 1) Editors, 2) External\nfact-checkers, 3) In-house fact-checkers, 4) Investigators and researchers, 5) Social media managers, and 6)\nAdvocators. Our findings highlight that the fact-checking process is a collaborative effort among various\nstakeholder groups and associated technological and informational infrastructures. By rendering visibility\nto the infrastructures, we reveal how fact-checking has evolved to include both short-term claims centric\nand long-term advocacy centric fact-checking. Our work also identifies key social and technical needs and\nchallenges faced by each stakeholder group. Based on our findings, we suggest that improving the quality of\nfact-checking requires systematic changes in the civic, informational, and technological contexts."},{"author":"Spencer Williams","email":"sw1918@cs.washington.edu","title":"An HCI Research Agenda for Online Science Communication ","status":"Done","link":"https://paper-video-nav.apps.allenai.org/reader/10.1145.3555591","conference":"https://programs.sigchi.org/cscw/2022/index/content/89565","abstract":"Social media, blogs, podcasts, and other computer-mediated communication technology have become an\nintegral way for the public to access and engage with research. However, despite the evolving challenges\nresearchers face navigating these platforms, and the high stakes of online science communication, relatively\nlittle HCI research has focused on understanding and supporting online science communication through\nthese participatory platforms. Through a review of the literature and a set of interviews with HCI researchers\n(n = 24), we identify challenges currently facing researchers who try to engage with the public about their\nwork, and establish a research agenda for HCI to study, design, and evaluate technology to support science\ncommunication. Specifically, we advocate for the design of tools to support audience analytics, automated\nsummary and outreach workflows, and providing quantitative and qualitative feedback about online outreach\nefforts, as well as additional research to elucidate the impacts of self-directed science communication efforts\nand the evolving roles of scientists on the participatory web. With shifting online platforms placing researchers\nin the role of advocates and participants in science communication, understanding and supporting these\ninteractions is now more important than ever."}]},"__N_SSG":true}