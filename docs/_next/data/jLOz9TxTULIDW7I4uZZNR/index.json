{"pageProps":{"papeos":[{"author":"Christina Pan","email":"capan@alumni.stanford.edu ","title":"Comparing the Perceived Legitimacy of Content\nModeration Processes: Contractors, Algorithms, Expert\nPanels, and Digital Juries","status":"Done","link":"https://paper-video-nav.apps.allenai.org/reader/10.1145.3512929","conference":"https://programs.sigchi.org/cscw/2022/index/content/87096","abstract":"While research continues to investigate and improve the accuracy, fairness, and normative appropriateness of content moderation processes on large social media platforms, even the best process cannot be effective if users reject its authority as illegitimate. We present a survey experiment comparing the perceived institutional legitimacy of four popular content moderation processes. We conducted a within-subjects experiment in which we showed US Facebook users moderation decisions and randomized the description of whether those decisions were made by paid contractors, algorithms, expert panels, or juries of users. Prior work suggests that juries will have the highest perceived legitimacy due to the benefits of judicial independence and democratic representation. However, expert panels had greater perceived legitimacy than algorithms or juries. Moreover, outcome alignment—agreement with the decision—played a larger role than process in determining perceived legitimacy. These results suggest benefits to incorporating expert oversight in content moderation and underscore that any process will face legitimacy challenges derived from disagreement about outcomes."},{"author":"Farnaz Jahanbakhsh","email":"farnazj@mit.edu","title":"Leveraging Structured Trusted-Peer Assessments to Combat\nMisinformation","status":"Done","link":"https://paper-video-nav.apps.allenai.org/reader/10.1145.3555637","conference":"https://programs.sigchi.org/cscw/2022/index/content/89614","abstract":"Platform operators have devoted significant effort to combating misinformation on behalf of their users. Users are also stakeholders in this battle, but their efforts to combat misinformation go unsupported by the platforms. In this work, we consider three new user affordances that give social media users greater power in their fight against misinformation: (1) the ability to provide structured accuracy assessments of posts, (2) user-specified indication of trust in other users, and (3) and user configuration of social feed filters according to assessed accuracy. To understand the potential of these designs, we conducted a need-finding survey of 192 people who share and discuss news on social media, finding that many already act to limit or combat misinformation, albeit by repurposing existing platform affordances that lack customized structure for information assessment. We then conducted a field study of a prototype social media platform that implements these user affordances as structured inputs to directly impact how and whether posts are shown. The study involved 14 participants who used the platform for a week to share news while collectively assessing their accuracy. We report on users' perception and use of these affordances. We also provide design implications for platforms and researchers based on our empirical observations."},{"author":"Haesoo Kim","email":"haesoo1108@gmail.com","title":"When Does it Become Harassment?: An Investigation of\nOnline Criticism and Calling Out in Twitter","status":"Done","link":"https://paper-video-nav.apps.allenai.org/reader/1122445.1122456","conference":"https://programs.sigchi.org/cscw/2022/index/content/89477","abstract":"Calling out, a phenomenon where people publicly broadcast their critiques of someone to a larger audience, has become increasingly common on social media. However, there have been concerns that it could develop into harassment, deteriorating the quality of public discourse by over-punishing individuals. To study this, we interviewed 32 Twitter users who had been called out, had called out, or had witnessed a calling out on Twitter. We found that a key determining factor that distinguishes criticism from harassment was the callee’s ability to respond to or engage with the criticism, and that different stakeholders hold different perspectives toward how online harassment is defined. We also discovered that the distinction between callers and callees was not absolute, and that there was high interchangeability of roles both within and across events. Through these findings, we discuss design implications for the platform in promoting healthy discourse while preventing toxic behavior on social media."}]},"__N_SSG":true}